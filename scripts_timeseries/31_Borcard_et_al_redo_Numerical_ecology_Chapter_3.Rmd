---
title: "31_Borcard_et_al_redo_Numerical_ecology_Chapter_3"
author: "Julia Gustavsen"
date: "30/04/2015"
output: html_document
---
## Chapter 3


```{r, echo=FALSE}
## add in the functions for the pairs 

panel.cor <- function(x, y, method="pearson", digits=3, cex.cor=1.2, no.col=FALSE)
{
 usr <- par("usr"); on.exit(par(usr))
 par(usr = c(0, 1, 0, 1))
	r <- cor(x, y, method=method)
	ra <- cor.test(x, y, method=method)$p.value
	txt <- round(r, digits)
	prefix <- ""
	if(ra <= 0.1) prefix <- "."
	if(ra <= 0.05) prefix <- "*"
	if(ra <= 0.01) prefix <- "**"
	if(ra <= 0.001) prefix <- "***"
	if(no.col)
	{
		color <- 1
		if(r < 0) { if(ra <= 0.001) sig <- 4 else sig <- 3 }
		else { if(ra <= 0.001) sig <- 2 else sig <- 1 }
	}
	else
	{
		sig <- 1
		if(ra <= 0.001) sig <- 2
		color <- 2
		if(r < 0) color <- 4
	}
	txt <- paste(txt, prefix, sep="\n")
	text(0.5, 0.5, txt, cex = cex.cor, font=sig, col=color)
}


## Put histograms on the diagonal
panel.hist <- function(x, no.col=FALSE, ...)
{
	usr <- par("usr"); on.exit(par(usr))
	par(usr = c(usr[1:2], 0, 1.5) )
	his <- hist(x, plot=FALSE)
	breaks <- his$breaks; nB <- length(breaks)
	y <- his$counts
	y <- y/max(y)
	if(no.col) rect(breaks[-nB], 0, breaks[-1], y, col="gray", ...)
	else rect(breaks[-nB], 0, breaks[-1], y, col="cyan", ...)
}


## Add black lowess curves to scatter plots
panel.smoothb <- function (x, y, col=par("col"), bg=NA, pch=par("pch"), 
	cex=1, col.smooth="black", span=2/3, iter=3, ...) 
{
	points(x, y, pch=pch, col=col, bg=bg, cex=cex)
	ok <- is.finite(x) & is.finite(y)
	if (any(ok)) 
	lines(stats::lowess(x[ok], y[ok], f=span, iter=iter), col=col.smooth, ...)
}
```

```{r}
library (ade4)
data (doubs)
spe <- doubs$fish
env <- doubs$env
spa <- doubs$xy
str(spe)
str(env)
str(spa)
```

## Chapter 3 Looking at R and Q mode-association measures

### Q mode -dissimilarity matrices and R mode dependence matrices
Think of a data box...
Q mode compares objects (among objects based on all observed descriptions)
R mode compares descriptors (based on all observed objects)
But what is an object and what is a descriptor?
"Such data sets are typically organized in tables with rows corresponding to objects and columns to descriptors"
"For instance, in community ecology, variables describing the biological communities (species) or the physical environment are measured for sampling sites (objects)"
So sites are objects? I think so. Descriptors are what are observed at the sites. So there are 2 different ways of comparing these things. Q mode 

#### In Q mode you look at the distance between objects (dissimilarity between pairs).

#### In R mode you use a measure of dependence among variables, such as covariance or correlation coefficient. 

(Better to use assymetrical coefficients when comparing species data objects because of the double zero problem, but with others it is ok to use symmetrical measures. )

## Section 3.3

All distances have been converted from dissimilarities to simmilarities. 

Bray-Curtis can be performed on untransformed data. But some will log transformed...I don't understand their reasoning in the book. Something about that the differences between orders of magnitude are masked. 
Hellinger reduces the importance of large abundances


```{r}
library(ade4)
library(vegan)  ## load after to avoid conflicts

library(gclus)
library(cluster)
library(FD)


## remove empty site 8
spe <- spe[-8,]
env <- env[-8,]
spa <- spa[-8,]

## Bray Curtis
spe.db <- vegdist(spe)
head(spe.db)

## Do it on log transformed abundances -dissimilarity matrix
spe.dbln <- vegdist(log1p(spe))
head(spe.dbln)

## Chord distance matrix
spe.norm <- decostand(spe, "nor") ## assigns normalized values to all the species
spe.dc <- dist(spe.norm)
head(spe.dc) ## I am surprised that some of these are over 1. What does that mean?

# Hellinger distance
spe.hel <- decostand(spe,"hel")
spe.dh <- dist(spe.hel)
head(spe.dh)

```


I skipped the section on the Jaccard and Sorensen index as it is pretty similar to the previous, but with these indices. 

```{r, echo=FALSE}
"coldiss" <- function(D, nc = 4, byrank = TRUE, diag = FALSE)
{
 require(gclus)

 if (max(D)>1) D <- D/max(D)

	if (byrank) {
		spe.color <- dmat.color(1-D, cm.colors(nc))
	}
	else {
		spe.color <- dmat.color(1-D, byrank=FALSE, cm.colors(nc))
	}

	spe.o <- order.single(1-D)
	speo.color <- spe.color[spe.o, spe.o]
	
	op <- par(mfrow=c(1,2), pty="s")

	if (diag) {
		plotcolors(spe.color, rlabels=attributes(D)$Labels, 
			main="Dissimilarity Matrix", 
			dlabels=attributes(D)$Labels)
		plotcolors(speo.color, rlabels=attributes(D)$Labels[spe.o], 
			main="Ordered Dissimilarity Matrix", 
			dlabels=attributes(D)$Labels[spe.o])
	}
	else {
		plotcolors(spe.color, rlabels=attributes(D)$Labels, 
			main="Dissimilarity Matrix")
		plotcolors(speo.color, rlabels=attributes(D)$Labels[spe.o], 
			main="Ordered Dissimilarity Matrix")
	}

	par(op)
}
```

Interesting plots to look at the similarity.
Magenta= dissimilarity close to 0 (max similarity)
Cyan=dissimilarity close to 1 (min similarity)

```{r}
## Bray-curtis similarity on row data
coldiss(spe.db, byrank=FALSE, diag=TRUE)

## log-transformed
coldiss(spe.dbln, byrank=FALSE, diag=TRUE)

coldiss(spe.dc, byrank=FALSE, diag=TRUE)

coldiss(spe.dh, byrank=FALSE, diag=TRUE)
```



## Q mode for quantitaive data other than species abundance data 

So here looking at the env data in a Q mode
-for data with a clear interpretation of double zeroes, the Euclidean distance is what you want.
-Euclidean distance is largely affected by the scale of the data
-So changing units will have a huge effect on the distance (eg. could be 1000x bigger)



```{r}
## remove the distance variable from the env dataset
env2 <- env[,-1]

## Euclidena distance matrix of the standardized env2 data frame

env.de <- dist(scale(env2)) ## scaled on the fly 
## scale -centers the columns of a numeric matrix
coldiss(env.de, diag=TRUE)

## Compare to the species data
coldiss(spe.dh, diag=TRUE)


## Euclidean distance based on the spatial coordinates (2D)
spa.de <- dist(spa) ## as the crow flies. 
coldiss(spa.de, diag=TRUE)

## Euclidean disatance matrix on distance from the source (1D)
das.df <- as.data.frame(env$dfs, row.names=rownames(env))
riv.de <- dist(das.df)
coldiss(riv.de, diag=TRUE)

```


### 3.3.4 Q modeL Binary Data (excluding species presence-absence data)
```{r}
## make up some data
var1 <- sample(c(rep(1,10), rep(0,20)))
var2 <- c(rep(0,15), rep(1,15))
var3 <- rep(c(1,1,1,0,0,0),5)
var4 <- rep(c(rep(1,5), rep(0,10)),2)
var5.1 <- sample(c(rep(1,7),rep(0,9)))
var5.2 <- c(rep(0,4), rep(1,10))
var5 <- c(var5.1,var5.2)


dat <- data.frame(var1,var2,var3,var4,var5)
dim(dat)

## matrix of simple matching coefficeints
dat.s1 <- dist.binary(dat, method=2)
coldiss(dat.s1, diag=TRUE)

```


### 3.3.5 dealing with nominal and categorical data.

Use Gower's index to look at the distance between mixed variables

```{r}
var.g1 <- rnorm(30,0,1)
var.g2 <- runif(30,0,5)
var.g3 <- gl(3,10)
var.g4 <- gl(2,5,30)

dat2 <- data.frame(var.g1, var.g2, var.g3, var.g4)
summary(dat2)

## Gower dissimilarity using daisy()
dat2.S15 <- daisy(dat2, "gower")
range(dat2.S15)
coldiss(dat2.S15, diag=TRUE)

## try with only te factors
dat2partial.S15 <- daisy(dat2[3:4], "gower")
coldiss(dat2partial.S15, diag=TRUE)
levels(factor(dat2partial.S15))

## with another package
library(FD)
dat2.S15.2 <- gowdis(dat2)
range(dat2.S15.2)
coldiss(dat2.S15.2)

## try again only with the 2 factors:
dat2partial.S15.2 <- gowdis(dat2[,3:4])
coldiss(dat2partial.S15.2, diag=TRUE)
levels(factor(dat2partial.S15.2))

```



## 3.4 R mode computing dependence matrices among variables

Looking at correlation among variables. Correlation-type coefficients used to compare variables in R mode. -Like Pearson, Spearman, Kendall for quant or semi-quant data and contingency stats for qualitative (chi-square and other forms)

What is chi-squared? Can't seem to understand the stuff. 

R-mode has us flipping the species matrix...

```{r}
spe.t <- t(spe) ## sites are now the columns

## Chi-square pre-transformation followed by Euclidean distance
spe.t.chi <- decostand(spe.t, "chi.square")
spe.t.D16 <- dist(spe.t.chi)
coldiss(spe.t.D16, diag=TRUE)
```

### 3.4.3 R mode: Quantitative and Ordinal Data (other than Species Abundances)

```{r}
#Pearson r linear correlation among environmental variables
env.pearson <- cor(env)
round(env.pearson, 2)

env.o <- order.single(env.pearson)
pairs(env[,env.o], lower.panel=panel.smooth, upper.panel=panel.cor, diag.panel=panel.hist, main="Pearson Correlation Matrix")

## Using Kendall tau rank correlation 
env.ken <- cor(env, method="kendall")
env.o <- order.single(env.ken)
pairs(env[,env.o], lower.panel=panel.smooth, upper.panel=panel.cor, method="kendall", diag.panel=panel.hist, main="Kendall Correlation Matrix")

```

### 3.4.4. R mode

## 3.5 Pre-transformations for species data

Legendre and Gallagher (2001) showed that if you transform your species data and then take the Euclidean distance you can use k-means, RDA, PCA, etc because the assymetry of you sites is kept. 

All the recommended types express data as relative abundances per sites in some way. -This removes the data from the total abundance per site. Hellinger relative abundance values are square-rooted- reduces more strongly the highest abundance values...

